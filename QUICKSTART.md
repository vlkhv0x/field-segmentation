# üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç - –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ–ª–µ–π

## üì• –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö

### EuroSAT Dataset

```bash
# –í–∞—Ä–∏–∞–Ω—Ç 1: –ü—Ä—è–º–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ
wget http://madm.dfki.de/files/sentinel/EuroSAT.zip
unzip EuroSAT.zip -d data/raw/

# –í–∞—Ä–∏–∞–Ω—Ç 2: Kaggle
kaggle datasets download -d apollo2506/eurosat-dataset
unzip eurosat-dataset.zip -d data/raw/EuroSAT/
```

## ‚ö° –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install -r requirements.txt

# –û–±—É—á–µ–Ω–∏–µ U-Net (50 —ç–ø–æ—Ö)
python src/train.py --epochs 50 --batch_size 16

# –û—Ü–µ–Ω–∫–∞ —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π
python src/evaluate.py --visualize --num_samples 10

# –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
python src/predict.py --image_path satellite.jpg --visualize
```

## üéØ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è

```bash
# –° –¥—Ä—É–≥–∏–º —ç–Ω–∫–æ–¥–µ—Ä–æ–º
python src/train.py --encoder resnet50 --epochs 50

# –ú–µ–Ω—å—à–∏–π batch –¥–ª—è —Å–ª–∞–±—ã—Ö GPU
python src/train.py --batch_size 8 --epochs 50

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ learning rate
python src/train.py --learning_rate 0.0005 --epochs 50
```

## üìä –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

- **Mean IoU**: 0.80-0.85
- **Mean Dice**: 0.88-0.92
- **Pixel Accuracy**: 90-93%
- **–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è**: 
  - GPU: 60-90 –º–∏–Ω—É—Ç
  - CPU: 5-8 —á–∞—Å–æ–≤

## üó∫Ô∏è –ö–ª–∞—Å—Å—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ EuroSAT

1. **AnnualCrop** - –û–¥–Ω–æ–ª–µ—Ç–Ω–∏–µ –∫—É–ª—å—Ç—É—Ä—ã
2. **Forest** - –õ–µ—Å
3. **HerbaceousVegetation** - –¢—Ä–∞–≤—è–Ω–∏—Å—Ç–∞—è —Ä–∞—Å—Ç–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
4. **Highway** - –î–æ—Ä–æ–≥–∏/—à–æ—Å—Å–µ
5. **Industrial** - –ü—Ä–æ–º—ã—à–ª–µ–Ω–Ω–∞—è –∑–æ–Ω–∞
6. **Pasture** - –ü–∞—Å—Ç–±–∏—â–µ
7. **PermanentCrop** - –ú–Ω–æ–≥–æ–ª–µ—Ç–Ω–∏–µ –∫—É–ª—å—Ç—É—Ä—ã
8. **Residential** - –ñ–∏–ª–∞—è –∑–æ–Ω–∞
9. **River** - –†–µ–∫–∞/–≤–æ–¥–æ—ë–º
10. **SeaLake** - –ú–æ—Ä–µ/–æ–∑–µ—Ä–æ

## üí° –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏

### Python API

```python
import tensorflow as tf
import numpy as np
from PIL import Image

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
model = tf.keras.models.load_model('models/best_model.h5')

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
img = Image.open('satellite.jpg').resize((256, 256))
img_array = np.array(img) / 255.0
img_batch = np.expand_dims(img_array, 0)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
prediction = model.predict(img_batch)[0]
segmentation_map = np.argmax(prediction, axis=-1)

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
unique, counts = np.unique(segmentation_map, return_counts=True)
for class_id, count in zip(unique, counts):
    percentage = (count / segmentation_map.size) * 100
    print(f"Class {class_id}: {percentage:.1f}%")
```

## üìê –ú–µ—Ç—Ä–∏–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏

**IoU (Intersection over Union)**
- –ú–µ—Ä–∞ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è –º–µ–∂–¥—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º –∏ ground truth
- –î–∏–∞–ø–∞–∑–æ–Ω: 0-1 (1 = –∏–¥–µ–∞–ª—å–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)

**Dice Coefficient**
- –ü–æ—Ö–æ–∂ –Ω–∞ IoU, –Ω–æ –±–æ–ª–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ —Ä–∞–∑–º–µ—Ä—É –æ–±—ä–µ–∫—Ç–∞
- –§–æ—Ä–º—É–ª–∞: 2 * |A ‚à© B| / (|A| + |B|)

**Pixel Accuracy**
- –ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∏–∫—Å–µ–ª–µ–π
- –ü—Ä–æ—Å—Ç–∞—è, –Ω–æ –º–æ–∂–µ—Ç –±—ã—Ç—å misleading –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤

## üîç –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ `reports/`:
- `segmentation_results.png` - –ø—Ä–∏–º–µ—Ä—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
- `training_history.json` - –∏—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
- `metrics_plot.png` - –≥—Ä–∞—Ñ–∏–∫–∏ –º–µ—Ç—Ä–∏–∫

## üêõ –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º

**–û—à–∏–±–∫–∞ –ø–∞–º—è—Ç–∏ (OOM)**
```bash
python src/train.py --batch_size 8  # –∏–ª–∏ 4
```

**–ù–∏–∑–∫–∏–π IoU**
- –£–≤–µ–ª–∏—á—å—Ç–µ epochs
- –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π encoder
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –º–∞—Å–æ–∫

**–î–æ–ª–≥–æ–µ –æ–±—É—á–µ–Ω–∏–µ**
- –£–º–µ–Ω—å—à–∏—Ç–µ —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–æ 128x128
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –ª–µ–≥–∫–∏–π encoder (mobilenetv2)

## üåü –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

### 1. –≠–∫—Å–ø–æ—Ä—Ç –º–∞—Å–æ–∫ –≤ GeoTIFF

```python
import rasterio
from rasterio.transform import from_bounds

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å –≥–µ–æ–ø—Ä–∏–≤—è–∑–∫–æ–π
with rasterio.open(
    'output.tif', 'w',
    driver='GTiff',
    height=mask.shape[0],
    width=mask.shape[1],
    count=1,
    dtype=mask.dtype,
    crs='+proj=latlong',
    transform=from_bounds(west, south, east, north, width, height)
) as dst:
    dst.write(mask, 1)
```

### 2. –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ CRF

```python
import pydensecrf.densecrf as dcrf

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ CRF –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
d = dcrf.DenseCRF2D(w, h, n_classes)
d.setUnaryEnergy(unary)
d.addPairwiseGaussian(sxy=3, compat=3)
Q = d.inference(5)
refined_mask = np.argmax(Q, axis=0).reshape((h, w))
```

### 3. –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

```bash
# –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ø–∞–ø–∫–µ
for img in data/test/*.jpg; do
    python src/predict.py --image_path "$img" --visualize
done
```

## üìö –ü–æ–ª–µ–∑–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [U-Net Paper](https://arxiv.org/abs/1505.04597)
- [Segmentation Models Documentation](https://segmentation-models.readthedocs.io/)
- [EuroSAT Paper](https://arxiv.org/abs/1709.00029)
- [Sentinel-2 Data](https://sentinel.esa.int/)

## üí¨ –ü–æ–¥–¥–µ—Ä–∂–∫–∞

–ü—Ä–∏ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏ –ø—Ä–æ–±–ª–µ–º –ø—Ä–æ–≤–µ—Ä—å—Ç–µ:
1. –í–µ—Ä—Å–∏–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫: `pip list`
2. –ù–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö: `ls data/raw/EuroSAT/`
3. –î–æ—Å—Ç—É–ø–Ω—É—é –ø–∞–º—è—Ç—å: `nvidia-smi` (–¥–ª—è GPU)
