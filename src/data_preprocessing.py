"""
–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–æ–ª–µ–π
"""

import os
import numpy as np
import pandas as pd
from pathlib import Path
from PIL import Image
import cv2
from sklearn.model_selection import train_test_split
import json


class FieldSegmentationPreprocessor:
    """–ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –¥–∞–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–æ–ª–µ–π"""
    
    def __init__(self, data_dir, img_size=(256, 256), batch_size=16):
        self.data_dir = Path(data_dir)
        self.img_size = img_size
        self.batch_size = batch_size
        self.class_names = []
        self.class_to_id = {}
        
    def load_eurosat_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ EuroSAT –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –º–∞—Å–æ–∫"""
        print("üîç –ó–∞–≥—Ä—É–∑–∫–∞ EuroSAT –¥–∞–Ω–Ω—ã—Ö...")
        
        image_paths = []
        labels = []
        
        for class_dir in sorted(self.data_dir.iterdir()):
            if class_dir.is_dir():
                class_name = class_dir.name
                if class_name not in self.class_names:
                    self.class_names.append(class_name)
                    self.class_to_id[class_name] = len(self.class_names) - 1
                
                for img_file in class_dir.glob('*.jpg'):
                    image_paths.append(str(img_file))
                    labels.append(class_name)
        
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ: {len(image_paths)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, {len(self.class_names)} –∫–ª–∞—Å—Å–æ–≤")
        return image_paths, labels
    
    def create_synthetic_masks(self, image_paths, labels, output_dir='data/processed/masks'):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –º–∞—Å–æ–∫ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        os.makedirs(output_dir, exist_ok=True)
        
        mask_paths = []
        print("üé® –°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏...")
        
        for img_path, label in zip(image_paths, labels):
            # –°–æ–∑–¥–∞—ë–º –º–∞—Å–∫—É: –≤—Å—ë –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–º–µ—á–µ–Ω–æ –æ–¥–Ω–∏–º –∫–ª–∞—Å—Å–æ–º
            mask = np.full(self.img_size, self.class_to_id[label], dtype=np.uint8)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–∞—Å–∫—É
            mask_filename = Path(img_path).stem + '_mask.png'
            mask_path = os.path.join(output_dir, mask_filename)
            Image.fromarray(mask).save(mask_path)
            mask_paths.append(mask_path)
        
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(mask_paths)} –º–∞—Å–æ–∫")
        return mask_paths
    
    def create_dataframe(self, image_paths, labels, mask_paths):
        """–°–æ–∑–¥–∞–Ω–∏–µ DataFrame"""
        df = pd.DataFrame({
            'image_path': image_paths,
            'mask_path': mask_paths,
            'class': labels
        })
        
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(df['class'].value_counts())
        
        return df
    
    def split_data(self, df, test_size=0.15, val_size=0.15, random_state=42):
        """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
        train_val_df, test_df = train_test_split(
            df, test_size=test_size, random_state=random_state, stratify=df['class']
        )
        
        val_size_adjusted = val_size / (1 - test_size)
        train_df, val_df = train_test_split(
            train_val_df, test_size=val_size_adjusted, 
            random_state=random_state, stratify=train_val_df['class']
        )
        
        print(f"\n‚úÇÔ∏è  –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ:")
        print(f"   Train: {len(train_df)}")
        print(f"   Val: {len(val_df)}")
        print(f"   Test: {len(test_df)}")
        
        return train_df, val_df, test_df
    
    def save_config(self, save_path='data/processed/config.json'):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        
        config = {
            'num_classes': len(self.class_names),
            'class_names': self.class_names,
            'class_to_id': self.class_to_id,
            'img_size': self.img_size
        }
        
        with open(save_path, 'w') as f:
            json.dump(config, f, indent=4)
        
        print(f"üíæ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {save_path}")
    
    def prepare_pipeline(self):
        """–ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏"""
        print("=" * 70)
        print("üõ∞Ô∏è  –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø –°–ï–ì–ú–ï–ù–¢–ê–¶–ò–ò")
        print("=" * 70)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞
        image_paths, labels = self.load_eurosat_data()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Å–æ–∫
        mask_paths = self.create_synthetic_masks(image_paths, labels)
        
        # DataFrame
        df = self.create_dataframe(image_paths, labels, mask_paths)
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ
        train_df, val_df, test_df = self.split_data(df)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        self.save_config()
        
        print("\n" + "=" * 70)
        print("‚úÖ –ü–û–î–ì–û–¢–û–í–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
        print("=" * 70)
        
        return train_df, val_df, test_df


def load_image_and_mask(image_path, mask_path, img_size=(256, 256)):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –º–∞—Å–∫–∏"""
    # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    img = Image.open(image_path).convert('RGB')
    img = img.resize(img_size)
    img_array = np.array(img) / 255.0
    
    # –ú–∞—Å–∫–∞
    mask = Image.open(mask_path)
    mask = mask.resize(img_size, Image.NEAREST)
    mask_array = np.array(mask)
    
    return img_array, mask_array


if __name__ == "__main__":
    preprocessor = FieldSegmentationPreprocessor(
        data_dir='data/raw/EuroSAT',
        img_size=(256, 256),
        batch_size=16
    )
    
    train_df, val_df, test_df = preprocessor.prepare_pipeline()
    print("\n‚úÖ –ü–∞–π–ø–ª–∞–π–Ω –≥–æ—Ç–æ–≤!")
